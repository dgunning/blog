{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a COVID-19 Research Engine\n",
    "> \"In this notebook we show how to build a search engine with NLP inside a notebook\"\n",
    "- toc: false\n",
    "- image: ../images/covidblue.png\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [notebooks,covid19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![COVID-19 Virus](../images/covidblue.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The COVID-19 Open Research Dataset Challenge dataset was created on Kaggle by a coalition of research groups to encourage Kagglers to help find solutions to the COVID-19 pandemic by making it easier to search thousands of medical research papers. This notebook was my contribution to the challenge. It contains a small notebook-oriented library called the CORD Research Engine_, which uses search and NLP technology to simplify searching the CORD Research Paper dataset for information that would help solve the current pandemic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "## Data files\n",
    "The _CORD-19_ dataset on Kaggle contains over 59,000 research papers. This notebook references about 2,000 of those papers, located in the directory _data_. Inside the data directory, the CORD Research data is located in the _CORD-19-research-challenge_ subdirectory. For the full dataset please see the competition page on Kaggle.\n",
    "\n",
    "## Navigating the data\n",
    "The original notebook was a Python kernel on Kaggle. On kaggle the data directory is _/kaggle/input_ and when you launch a new notebook you are given a block of code to view the data in the directory.\n",
    "\n",
    "```\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "```\n",
    "\n",
    "#### The Data Directory\n",
    "![Data directory](../images/datadir.png)\n",
    "\n",
    "Instead of the code above we will use `pathlib` for navigating the filesystem because it is a little bit easier to use than `os.path`. From pathlib we will use the `Path` and `PurePath` classes. The `Path` class provides almost all the functionality we need except that it cannot be passed directly into _pandas.read_csv_ as can be done with the `PurePath`. \n",
    "\n",
    "Now we can create a Path object at the location of the CORD research data and view the contents of that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/CORD-19-research-challenge/biorxiv_medrxiv'),\n",
       " WindowsPath('data/CORD-19-research-challenge/comm_use_subset'),\n",
       " WindowsPath('data/CORD-19-research-challenge/cord_19_embeddings.csv'),\n",
       " WindowsPath('data/CORD-19-research-challenge/custom_license'),\n",
       " WindowsPath('data/CORD-19-research-challenge/metadata.csv'),\n",
       " WindowsPath('data/CORD-19-research-challenge/noncomm_use_subset')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path, PurePath\n",
    "data_path = Path('data/CORD-19-research-challenge')\n",
    "list(data_path.glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _CORD-19_ data directory contains four sub-directories, the JSON contents of the research papers, and a _metadata.csv_ file with the metadata for all the research papers. For the actual details of the CORD Research papers dataset, see the description on the Kaggle site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Engine Design\n",
    "\n",
    "## A tale of two indexes\n",
    "We will build two *indexes* into the data: one for _search_, and one for _similarity_. An index is just a data structure that provides a way to sort some data. In our case, for search, we want to provide a search term to the index and have it return a list of the research papers, sorted by most relevant to the search term.  \n",
    "\n",
    "With the _similarity_ index, the goal is to provide a research paper as input and have the index return a list of papers sorted by the most similar to that paper. \n",
    "\n",
    "In the real world, and for applications that you may write, you may encounter those two use cases, so we will show the best techniques to fulfill the requirements. *Search* and *Similarity* are related but not identical areas, and both the indexes we will build are better at one than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-Oriented Design\n",
    "An object-oriented design is rarely used with notebooks, and for good reason. A notebook is a hybrid of a Python script and a layout template, which both operate in a top to bottom way. Objects are usually meant to be defined in a certain location or context and interacted with multiple times during the course of a program. This is exactly what we want to do here; we intend to create a Research Engine and use it to find research papers during the course of a single session.\n",
    "\n",
    "There are two main objects in our design: `ResearchPapers` and `Paper`. The `ResearchPapers` class will load and maintain the list of research papers, while `Paper` will allow us to work with a single research paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchPapers:\n",
    "\n",
    "    def __init__(self, metadata, data_dir='data'):\n",
    "        pass\n",
    "    \n",
    "class Paper:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Research Papers\n",
    "\n",
    "\n",
    "We start with the _metadata.csv_ since this contains the master list of all the research papers and important information about each paper. Some Kaggle kernels started by loading the research papers from the JSON files, but the metadata is considerably smaller, and starting with the metadata might allow us to only load a research paper from a JSON file if required, thereby saving significantly on computational resources. \n",
    "\n",
    "## Load Metadata\n",
    "The `load_metadata` function is straightforward - it uses `pandas.read_csv()` to load the metadata.csv file. Along the way it changes the data types for the _Microsoft Academic Paper ID_ and _pubmed_id_ columns. It also renames a couple of columns, which is optional, and only to make browsing the data a little easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    @staticmethod\n",
    "    def load_metadata(data_path=None):\n",
    "        if not data_path:\n",
    "            data_path = find_data_dir()\n",
    "\n",
    "            print('Loading metadata from', data_path)\n",
    "            metadata_path = PurePath(data_path) / 'metadata.csv'\n",
    "            dtypes = {'Microsoft Academic Paper ID': 'str', 'pubmed_id': str}\n",
    "            renames = {'source_x': 'source', 'has_full_text': 'has_text'}\n",
    "            # Load the metadata using read.csv\n",
    "            metadata = pd.read_csv(metadata_path, dtype=dtypes, \n",
    "                                   low_memory=False,\n",
    "                                   parse_dates=['publish_time']).rename(columns=renames)\n",
    "            metadata = clean_metadata(metadata)\n",
    "            return metadata\n",
    "    \n",
    "```\n",
    "Within `load_metadata` we call `clean_metadata`. This function is a data cleaning pipeline that fixes some of the issues with the Kaggle data by using a pipeline of data cleaning functions. Notice that each function is specfic to a task, and named specifically for that task, which makes it simple to remove or add cleaning functions. This is important since a new version of the CORD research data is released every week, with new data fixes, so if you can quickly modify your data pipeline, it gives you an advantage.\n",
    "\n",
    "## Clean Metadata\n",
    "\n",
    "```python\n",
    "def clean_metadata(metadata):\n",
    "    print('Cleaning metadata')\n",
    "    return metadata.pipe(start) \\\n",
    "        .pipe(clean_title) \\\n",
    "        .pipe(clean_abstract) \\\n",
    "        .pipe(rename_publish_time) \\\n",
    "        .pipe(add_date_diff) \\\n",
    "        .pipe(drop_missing) \\\n",
    "        .pipe(fill_nulls) \\\n",
    "        .pipe(apply_tags)\n",
    "```\n",
    "\n",
    "Each function in the `clean_metadata` pipeline accepts a dataframe and returns the dataframe after modification. The functions are connected by the pandas dataframe `pipe` function, which is designed for this use case of connecting functions sequentially. At the start of the pipeline is a special function called `start` which is defined as:\n",
    "\n",
    "```python\n",
    "def start(data):\n",
    "    return data.copy()\n",
    "```\n",
    "\n",
    "This returns a copy of the data at the start of a data pipeline. This is very important; it makes sure that the initial data is unchanged and enables you to rerun your notebook from any point without worrying that your data has changed in a way that breaks it. This is a pattern I learned from the presentation **[Untitled12.ipynb](https://www.youtube.com/watch?v=yXGCKqo5cEY)  by Vincent D Warmerdam** at _PyData Eindhoven 2019_\n",
    "\n",
    "Each subsequent function in the pipeline accepts a dataframe and returns a dataframe. Here is `clean_title`:\n",
    "\n",
    "```python\n",
    "\n",
    "def clean_title(data):\n",
    "    # Set junk titles to ''\n",
    "    title_relevant = data.title.fillna('').str.match(_relevant_re_, case=False)\n",
    "    title_short = data.title.fillna('').apply(len) < 30\n",
    "    title_junk = title_short & ~title_relevant\n",
    "    data.loc[title_junk, 'title'] = ''\n",
    "    return data\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load function\n",
    "After loading the metadata, we have the `load` function. This is the static function on the `ResearchPapers` class that actually creates the ResearchPapers instance using `ResearchPapers.load()`.\n",
    "\n",
    "```python\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, index=None):\n",
    "        data_path = find_data_dir()\n",
    "        metadata = cls.load_metadata(data_path)\n",
    "        return cls(metadata, data_path, index=index)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "While the `clean_metadata` function does some text preprocessing, it does that in relation to the _metadata.csv_ file that is released by Kaggle to remove any data issues it might have. We still need to do text preprocessing to prepare the text of the research papers for storing in the _search_ and _similarity_ indexes. Text preprocessing is a necessary part of NLP projects, and, despite the fact that there are a lot of utilities available in NLP libraries to preprocess test, it is still part of the art of being an NLP practictioner. For example, the regex below was hand-crafted with input from Google searches, and a lot of trial and error. I found, for example, that the text prepeocessing that came with gensim was hand-rolled. You may or may not need to follow a similar process for your own text preprocessing, depending on your judgement.  \n",
    "\n",
    "```python\n",
    "\n",
    "TOKEN_PATTERN = re.compile('^(20|19)\\d{2}|(?=[A-Z])[\\w\\-\\d]+$', re.IGNORECASE)\n",
    "\n",
    "def replace_punctuation(text):\n",
    "    t = re.sub('\\(|\\)|:|,|;|\\.|’|”|“|\\?|%|>|<|≥|≤|~|`', '', text)\n",
    "    t = re.sub('/', ' ', t)\n",
    "    t = t.replace(\"'\", '')\n",
    "    return t\n",
    "\n",
    "def clean(text):\n",
    "    t = text.lower()\n",
    "    t = replace_punctuation(t)\n",
    "    return t\n",
    "               \n",
    "def tokenize(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return [word for word in words\n",
    "            if len(word) > 1\n",
    "            and not word in SIMPLE_STOPWORDS\n",
    "            and TOKEN_PATTERN.match(word)\n",
    "            ]\n",
    "\n",
    "def preprocess(text):\n",
    "    t = clean(text)\n",
    "    tokens = tokenize(t)\n",
    "    return tokens\n",
    "```\n",
    "\n",
    "### The preprocess function\n",
    "\n",
    "Regardless, every NLP project requires a `preprocess` or equivalent function. Our `preprocess` function converts the text to lowercase, removes punctuation, and converts the text to tokens. What is very important is that the identical preprocess function be used when preparing the text in batch mode as when using it in query mode. So the preprocess function will be used again on each search query to match accurately against what is stored in the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "## Parallel Processing\n",
    "\n",
    "As of the May 2nd data release the _CORD Research Paper_ dataset was over **8GB** in size, with more than 59,000 metadata records and well over 60,000 research papers on disk. In order to process the data in a reasonable amount of time, we added a utility function that will run a given function on a list of data using as many cores that are available.\n",
    "\n",
    "```python\n",
    "\n",
    "def parallel(func, arr: Collection, max_workers: int = None, leave=False):\n",
    "    \"Call `func` on every element of `arr` in parallel using `max_workers`.\"\n",
    "    max_workers = ifnone(max_workers, multiprocessing.cpu_count())\n",
    "    progress_bar = tqdm(arr)\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures_to_index = {ex.submit(func, o): i for i, o in enumerate(arr)}\n",
    "        results = []\n",
    "        for f in as_completed(futures_to_index):\n",
    "            results.append((futures_to_index[f], f.result()))\n",
    "            progress_bar.update()\n",
    "        for n in range(progress_bar.n, progress_bar.total):\n",
    "            time.sleep(0.1)\n",
    "            progress_bar.update()\n",
    "        results.sort(key=lambda x: x[0])\n",
    "    return [result for i, result in results]\n",
    "\n",
    "```\n",
    "\n",
    "For example, if we have a list of JSON files and we want to convert that to a ist of tokenized text we can do:\n",
    "\n",
    "```python\n",
    "\n",
    "def get_tokens(cord_path):\n",
    "    cord_uid, path = cord_path\n",
    "    if isinstance(path, Path):\n",
    "        tokens = preprocess(load_text(path))\n",
    "        return cord_uid, tokens\n",
    "    return cord_uid, np.nan\n",
    "\n",
    "cord_tokens = parallel(get_tokens, cord_paths)\n",
    "```\n",
    "\n",
    "Reading and tokenizing each of the over 60,000 JSON files is a very expensive operation, so we want to distribute this load across our CPU cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the Metadata\n",
    "The `pandas` function `describe` can be used to gather information about _series_ and _dataframes_. \n",
    "\n",
    "This is what `describe` shows when you use it on the metadata without doing any special type of conversions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.404000e+03</td>\n",
       "      <td>3.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.214187e+07</td>\n",
       "      <td>2.706621e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.717728e+06</td>\n",
       "      <td>4.306890e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.700200e+04</td>\n",
       "      <td>1.559092e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.726375e+07</td>\n",
       "      <td>2.315523e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.375861e+07</td>\n",
       "      <td>3.003704e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.839937e+07</td>\n",
       "      <td>3.004938e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.230300e+07</td>\n",
       "      <td>3.006646e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pubmed_id  Microsoft Academic Paper ID\n",
       "count  1.404000e+03                 3.600000e+01\n",
       "mean   2.214187e+07                 2.706621e+09\n",
       "std    7.717728e+06                 4.306890e+08\n",
       "min    2.700200e+04                 1.559092e+09\n",
       "25%    1.726375e+07                 2.315523e+09\n",
       "50%    2.375861e+07                 3.003704e+09\n",
       "75%    2.839937e+07                 3.004938e+09\n",
       "max    3.230300e+07                 3.006646e+09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv(PurePath(data_path) / 'metadata.csv')\n",
    "metadata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a bit limiting, so we will write a function that provides more information than what is available using `describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cord.core import describe_dataframe\n",
    "\n",
    "describe_dataframe(metadata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResearchPapers init\n",
    "\n",
    "Now we are at `ResearchPapers.__init__()`. The `ResearchPapers` instance is constructed with a metadata dataframe, which is the dataframe we parsed in `load_metadata`. A `ResearchPapers` instance can also be constructed with a subset of the metadata, meaning that we can create an instance containing only COVID-19 related papers, or papers published by **Elsevier** or any other subset of the metadata that we are interested in. We will show how to use this functionality later.\n",
    "\n",
    "We can construct the _BM25_ index from the papers referenced by the metadata. Each metadata row has an _abstract_ column, which contains the abstract of the research paper, which we can preprocess into the index tokens needed by the index. We can, alternatively, create the index tokens from the full text content of the paper, which we load from disk. The full text content gives the potential for a more accurate search, with the tradeoff that it takes a much longer time to build the index. To enable this tradeoff, the `load` function accepts a parameter `index`, which deteremines which index strategy to use. `ResearchPapers.load(index=\"text\")` loaded and indexed from the JSON file contents, while `ResearchPapers.load(index\"abstract\")` used the metadata abstract. On a Kaggle instance it took approximately **100** seconds to index from the abstracts versus over **2,000** seconds to index from the JSON texts, though it was about three times faster for each operation on my local laptop. \n",
    "\n",
    "To save on the time to load from the JSON texts the _CORD_ library, JSON index tokens were processed offline and saved to parquet files. These parquet files were then loaded whenever the option `index=\"text\"` was selected.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    " def __init__(self, metadata, data_dir='data', index='abstract', view='html'):\n",
    "        self.data_path = Path(data_dir)\n",
    "        self.num_results = 10\n",
    "        self.view = view\n",
    "        self.metadata = metadata\n",
    "        if 'index_tokens' not in metadata:\n",
    "            print('\\nIndexing research papers')\n",
    "            if any([index == t for t in ['text', 'texts', 'content', 'contents']]):\n",
    "                tick = time.time()\n",
    "                _set_index_from_text(self.metadata, data_dir)\n",
    "                print(\"Finished indexing in\", int(time.time() - tick), 'seconds')\n",
    "            else:\n",
    "                print('Creating the BM25 index from the abstracts of the papers')\n",
    "                print('Use index=\"text\" if you want to index the texts of the paper instead')\n",
    "                tick = time.time()\n",
    "                self.metadata['index_tokens'] = metadata.abstract.apply(preprocess)\n",
    "                tock = time.time()\n",
    "                print('Finished Indexing in', round(tock - tick, 0), 'seconds')\n",
    "\n",
    "        # Create BM25 search index\n",
    "        self.bm25 = _get_bm25Okapi(self.metadata.index_tokens)\n",
    "\n",
    "```\n",
    "\n",
    "## Python Objects wrapping dataframes\n",
    "A pattern that is repeated throughout the project is to have a dataframe as a member of a python object. The python object controls access to the dataframe and provides useful functionality, while the dataframe acts as a local database. There are many use cases that fit this pattern where you load read-only data into a dataframe and wrap python code around it. In our case the `ResearchPapers` class acts like a miniature application that accesses a local in-memory database. We also do this with the `SearchResults` object, which wraps a dataframe of the search results.\n",
    "\n",
    "The most important line above `self.metadata = metadata` sets the dataframe as an instance member. The primary use is to load all the research papers from the _metadata.csv_, in which case we will have all 50,000+ research papers. Note that we can pass a metadata dataframe of any number of records, meaning that we can make subsets of `ResearchPapers`. This enables the ability to select only a subset of research papers, e.g. `source==\"Elsevier\"`, then make a copy of the `ResearchPapers` with the smaller number of records.\n",
    "\n",
    "```python\n",
    "    \n",
    "    def query(self, query):\n",
    "        data = self.metadata.query(query)\n",
    "        return self._make_copy(data)\n",
    "    \n",
    "    def _make_copy(self, new_data):\n",
    "        return ResearchPapers(metadata=new_data.copy(),\n",
    "                              data_dir=self.data_path,\n",
    "                              view=self.view)\n",
    "```\n",
    "We will see how this pattern is used in more detail later in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing Research Papers\n",
    "Now that we have completed our basic code, we can see the load in action. We will start with loading from the abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cord import ResearchPapers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing from Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from data\\CORD-19-research-challenge\n",
      "Cleaning metadata\n",
      "Applying tags to metadata\n",
      "\n",
      "Indexing research papers\n",
      "Creating the BM25 index from the abstracts of the papers\n",
      "Use index=\"text\" if you want to index the texts of the paper instead\n",
      "Finished Indexing in 7.0 seconds\n"
     ]
    }
   ],
   "source": [
    "papers = ResearchPapers.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing from Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from data\\CORD-19-research-challenge\n",
      "Cleaning metadata\n",
      "Applying tags to metadata\n",
      "\n",
      "Indexing research papers\n",
      "Creating the BM25 index from the text contents of the papers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b4b93026ee4ab08b5b5e30217acaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=350.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e768699978048928cabd144bcd5145d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=96.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9da133d9cf45ceb658efe859f1af06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8fa1ec024e4578aad12b82773e9317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1220.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2006 papers that will be indexed using the abstract instead of the contents\n",
      "Finished indexing in 148 seconds\n"
     ]
    }
   ],
   "source": [
    "papers = ResearchPapers.load(index='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>CORD 19 Research Papers</h3>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Papers</th>\n",
       "      <th>Oldest</th>\n",
       "      <th>Newest</th>\n",
       "      <th>SARS-COV-2</th>\n",
       "      <th>SARS</th>\n",
       "      <th>Coronavirus</th>\n",
       "      <th>Virus</th>\n",
       "      <th>Antivirals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>2006</td>\n",
       "      <td>1967-03-31</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>227</td>\n",
       "      <td>134</td>\n",
       "      <td>384</td>\n",
       "      <td>1133</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<hr/>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A model of tripeptidyl-peptidase I (CLN2), a u...</td>\n",
       "      <td>: Tripeptidyl-peptidase I, also known as CLN2,...</td>\n",
       "      <td>BMC Struct Biol</td>\n",
       "      <td>Wlodawer, Alexander; Durell, Stewart R; Li, Mi...</td>\n",
       "      <td>2003-11-11</td>\n",
       "      <td>16 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SARS and hospital priority setting: a qualitat...</td>\n",
       "      <td>: Priority setting is one of the most difficul...</td>\n",
       "      <td>BMC Health Serv Res</td>\n",
       "      <td>Bell, Jennifer AH; Hyland, Sylvia; DePellegrin...</td>\n",
       "      <td>2004-12-19</td>\n",
       "      <td>15 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trade and Health: Is the Health Community Read...</td>\n",
       "      <td>There are greater tensions than ever before be...</td>\n",
       "      <td>PLoS Med</td>\n",
       "      <td>Lee, Kelley; Koivusalo, Meri</td>\n",
       "      <td>2005-01-25</td>\n",
       "      <td>15 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reference gene selection for quantitative real...</td>\n",
       "      <td>Ten potential reference genes were compared fo...</td>\n",
       "      <td>Virol J</td>\n",
       "      <td>Radonić, Aleksandar; Thulke, Stefanie; Bae, Hi...</td>\n",
       "      <td>2005-02-10</td>\n",
       "      <td>15 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia's international health relations in ...</td>\n",
       "      <td>A survey for the year 2003 of significant deve...</td>\n",
       "      <td>Aust New Zealand Health Policy</td>\n",
       "      <td>Barraclough, Simon</td>\n",
       "      <td>2005-02-21</td>\n",
       "      <td>15 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Chloroquine : pas d’efficacité sur le virus Ebola</td>\n",
       "      <td>Chloroquine : pas d’efficacité sur le virus Ebola</td>\n",
       "      <td>Revue Francophone des Laboratoires</td>\n",
       "      <td></td>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>4 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>Multiplex PCR tests sentinel the appearance of...</td>\n",
       "      <td>Background Since the turn of the century seve...</td>\n",
       "      <td>Journal of Clinical Virology</td>\n",
       "      <td>Mahony, James B.; Hatchette, Todd; Ojkic, Davo...</td>\n",
       "      <td>2009-07-31</td>\n",
       "      <td>11 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Identification of a New Antizyme mRNA +1 Frame...</td>\n",
       "      <td>The expression of eukaryotic antizyme genes r...</td>\n",
       "      <td>Journal of Molecular Biology</td>\n",
       "      <td>Ivanov, Ivaylo P; Anderson, Christine B; Geste...</td>\n",
       "      <td>2004-06-04</td>\n",
       "      <td>16 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>Antiviral responses against chicken respirator...</td>\n",
       "      <td>Some of the respiratory viral infections in c...</td>\n",
       "      <td>Cytokine</td>\n",
       "      <td>Barjesteh, Neda; O'Dowd, Kelsey; Vahedi, Seyed...</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Biochemical evidence for the presence of mixed...</td>\n",
       "      <td>Coronavirus envelope (E) protein is a small i...</td>\n",
       "      <td>FEBS Letters</td>\n",
       "      <td>Yuan, Q.; Liao, Y.; Torres, J.; Tam, J.P.; Liu...</td>\n",
       "      <td>2006-05-29</td>\n",
       "      <td>14 years ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2006 rows × 6 columns</p>\n",
       "</div>\n",
       "<style>\n",
       "h3 {color: #4169E1}\n",
       "</style>"
      ],
      "text/plain": [
       "<cord.cord19.ResearchPapers at 0x1574ca44e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Search Index\n",
    "The search index is built on a BM25 Okapi libray called _rank_bm25_.\n",
    "\n",
    "An implementation of BM25 is also available in gensim, but I found _rank_bm25_ was simple to implement.\n",
    "\n",
    "- [rank_bm25](https://pypi.org/project/rank-bm25/)\n",
    "- [Dorian Brown (author of rank_bm25)](https://github.com/dorianbrown)\n",
    "\n",
    "## What is BM25 Okapi?\n",
    "BM25 stands for _Best Match the 25th version_ and is a text search algorithm first developed in 1994. Okapi stands for the _Okapi information retrieval system_, implemented at London's City University in the 1980s and 1990s on which BM25 was used.\n",
    "\n",
    "It is one of the best search algorithms available, and Lucene and its derivatives, Solr and ElasticSearch switched to a BM25 variant around 2015.\n",
    "\n",
    "\n",
    "\n",
    "## Creating the BM25 Index\n",
    "\n",
    "The heart of this notebook, the one forked over 400 times on Kaggle, is this line of code.\n",
    "\n",
    "```python\n",
    "BM25Okapi(index_tokens.tolist())\n",
    "```\n",
    "This creates a new _BM25Okapi_ index on the index_tokens. The index accepts a list of tokens, with each item in the list representing a single tokenized research paper. This is as simple as you can get for a bit of technology that is also used in **ElasticSearch** software.\n",
    "\n",
    "The actual implementation in the library is just slightly more complicated, accounting for the edge case of creating a `ResearchPapers` instance with no papers inside. (This can happen, as we see below, if our API is so flexible that it allows a user to do this).\n",
    "\n",
    "```python\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def _get_bm25Okapi(index_tokens):\n",
    "    has_tokens = index_tokens.apply(len).sum() > 0\n",
    "    if not has_tokens:\n",
    "        index_tokens.loc[0] = ['no', 'tokens']\n",
    "    return BM25Okapi(index_tokens.tolist())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching Papers\n",
    "\n",
    "The `search` function is defined below. We preprocess the search string and then get the doc_scores (the search relevance score) from the BM25 index for all documents in the index. Then we get the dataframe locations of the most relevant papers, do some additional filtering, then return the top _n_ results.\n",
    "\n",
    "```python\n",
    "    def search(self, search_string,\n",
    "               num_results=10,\n",
    "               covid_related=False,\n",
    "               start_date=None,\n",
    "               end_date=None,\n",
    "               view='html'):\n",
    "        n_results = num_results or self.num_results\n",
    "        \n",
    "        # Preprocess the search string\n",
    "        search_terms = preprocess(search_string)\n",
    "        \n",
    "        # Get the doc scores from the BM25 index\n",
    "        doc_scores = self.bm25.get_scores(search_terms)\n",
    "\n",
    "        # Get the index from the doc scores sorted by most relevant\n",
    "        ind = np.argsort(doc_scores)[::-1]\n",
    "        \n",
    "        # Sort the metadata using the sorted index above\n",
    "        results = self.metadata.iloc[ind].copy()\n",
    "        \n",
    "        # Round the doc scores, in case we use the score in the display \n",
    "        results['Score'] = doc_scores[ind].round(1)\n",
    "\n",
    "        # Filter covid related\n",
    "        if covid_related:\n",
    "            results = results[results.covid_related]\n",
    "\n",
    "        # Filter by dates - start date\n",
    "        if start_date:\n",
    "            results = results[results.published >= start_date]\n",
    "        # end data\n",
    "        if end_date:\n",
    "            results = results[results.published < end_date]\n",
    "\n",
    "        # Show only up to n_results\n",
    "        results = results.head(num_results)\n",
    "\n",
    "        # Create the final results\n",
    "        results = results.drop_duplicates(subset=['title'])\n",
    "\n",
    "        # Return Search Results\n",
    "        return SearchResults(results, self.data_path, view=view)\n",
    "\n",
    "```\n",
    "\n",
    "Here is the code run outside of the function, with print statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_tokens ['mother', 'child', 'transmission']\n",
      "doc_scores [0. 0. 0. ... 0. 0. 0.]\n",
      "ind [1451 1543   82 ... 1320 1322    0]\n"
     ]
    }
   ],
   "source": [
    "from cord.text import preprocess\n",
    "import numpy as np\n",
    "\n",
    "search_query = 'Mother to child transmission'\n",
    "search_tokens = preprocess(search_query)\n",
    "print('search_tokens', search_tokens)\n",
    "\n",
    "doc_scores = papers.bm25.get_scores(search_tokens)\n",
    "print('doc_scores', doc_scores)\n",
    "\n",
    "ind = np.argsort(doc_scores)[::-1]\n",
    "print('ind', ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Similarity Index\n",
    "\n",
    "Included with the _CORD-19 Research Dataset_ is a CSV file containing the document embeddings vectors for the papers in the dataset. Each vector is a 768-dimension vector representing  what a neural network has learned about that research paper, and, effectively, it is a signature or a fingerprint of that research paper. This vector can be used to build our _similarity index_ and allow us to find similar papers for any given research paper.\n",
    "\n",
    "![Search2d](../images/search2d.png)\n",
    "\n",
    "The embeddings CSV file is large—over 700MB in the real dataset. For this notebook we have created a smaller CSV file with only the embeddings for the research papers included with the notebook. If you load and look at the embeddings, you will see 769 columns, one for each of the 768-dimension vector, plus the *cord_uid*.  (The *cord_uid* is the unique identifier for a research paper in the dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1824, 769)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5o38ihe0</th>\n",
       "      <th>-5.601012229919434</th>\n",
       "      <th>-4.197016716003418</th>\n",
       "      <th>2.3068416118621826</th>\n",
       "      <th>5.485584259033203</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xvi5miqw</td>\n",
       "      <td>-1.932757</td>\n",
       "      <td>-4.252481</td>\n",
       "      <td>-4.315052</td>\n",
       "      <td>4.177907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zl5lgcog</td>\n",
       "      <td>2.447766</td>\n",
       "      <td>-2.379109</td>\n",
       "      <td>-0.537503</td>\n",
       "      <td>4.555745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5o38ihe0  -5.601012229919434  -4.197016716003418  2.3068416118621826  \\\n",
       "0  xvi5miqw           -1.932757           -4.252481           -4.315052   \n",
       "1  zl5lgcog            2.447766           -2.379109           -0.537503   \n",
       "\n",
       "   5.485584259033203  \n",
       "0           4.177907  \n",
       "1           4.555745  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_path = data_path / 'cord_19_embeddings.csv'\n",
    "embeddings = pd.read_csv(embeddings_path)\n",
    "display(embeddings.shape)\n",
    "\n",
    "## Look at the first 2 rows and 5 columns\n",
    "embeddings.iloc[:2, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the data again, but this time add the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings of shape (1825, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cord_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5o38ihe0</th>\n",
       "      <td>-5.601012</td>\n",
       "      <td>-4.197017</td>\n",
       "      <td>2.306842</td>\n",
       "      <td>5.485584</td>\n",
       "      <td>3.822709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xvi5miqw</th>\n",
       "      <td>-1.932757</td>\n",
       "      <td>-4.252481</td>\n",
       "      <td>-4.315052</td>\n",
       "      <td>4.177907</td>\n",
       "      <td>-3.749875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4\n",
       "cord_uid                                                  \n",
       "5o38ihe0 -5.601012 -4.197017  2.306842  5.485584  3.822709\n",
       "xvi5miqw -1.932757 -4.252481 -4.315052  4.177907 -3.749875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VECTOR_COLS = [str(i) for i in range(768)]\n",
    "COLUMNS = ['cord_uid'] + VECTOR_COLS\n",
    "embeddings = pd.read_csv(embeddings_path, names=COLUMNS).set_index('cord_uid')\n",
    "print('Loaded embeddings of shape', embeddings.shape)\n",
    "\n",
    "## Look at the first 2 rows and 5 columns\n",
    "embeddings.iloc[:2, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Annoy Index\n",
    "_Annoy_ is a library for building an index of vectors so that the nearest neighbors to that vector can be easily found. This library is used at **Spotify** to find music recommendations, so it is one of the best technologies we can possibly use to find similar papers.\n",
    "\n",
    "To build an _annoy_ index, you first create it with the vector size that you want to store in the index, then add each vector to the index, then build.\n",
    "\n",
    "```python\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "\n",
    "VECTOR_SIZE = 40\n",
    "annoy_index = AnnoyIndex(VECTOR_SIZE, 'angular')  # Length of item vector that will be indexed\n",
    "for i, vector in enumerate(vectors):\n",
    "    annoy_index.add_item(i, vector)\n",
    "\n",
    "annoy_index.build(10) # 10 trees\n",
    "annoy_index.save('test.ann')\n",
    "\n",
    "```\n",
    "\n",
    "### Reduce Vector Dimensions\n",
    "For the index we wanted to create, we thought 768 dimensions was too much, especially since it meant that the resulting index would be very large on disk, and also too large to fit into a Git repository. Therefore we used _PCA_ to reduce the dimensions to 192, and those **192** dimensional vectors are stored in the _Annoy Index_.\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def downsample(docvectors, dimensions=2):\n",
    "    print(f'Downsampling to {dimensions}D embeddings')\n",
    "    pca = PCA(n_components=dimensions, svd_solver='full')\n",
    "    docvectors_downsampled = pca.fit_transform(docvectors)\n",
    "    return np.squeeze(docvectors_downsampled), pca\n",
    "```\n",
    "\n",
    "### Getting Similar Vectors\n",
    "Once we have the _annoy index_, we use it to find similar papers using the `similar papers` function. _Annoy_ has two functions for finding similar papers: `get_nns_by_item` and `get_nns_by_vector`. In our function we use `get_nns_by_item`.\n",
    "\n",
    "```python\n",
    "def similar_papers(paper_id, num_items=config.num_similar_items):\n",
    "    from .vectors import SPECTOR_SIMILARITY_INDEX\n",
    "    index = paper_id if isinstance(paper_id, int) else get_index(paper_id)\n",
    "    if not index:\n",
    "        return []\n",
    "    similar_indexes = SPECTOR_SIMILARITY_INDEX.get_nns_by_item(index, num_items, search_k=config.search_k)\n",
    "    similar_cord_uids = document_vectors.iloc[similar_indexes].index.values.tolist()\n",
    "    return [id for id in similar_cord_uids if not id == paper_id]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying objects in a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the search function we returned a `SearchResults` object that contained a dataframe with the search results. This is a common pattern used in the notebook—often a dataframe is wrapped inside of an object. \n",
    "\n",
    "The reason for this pattern is to control how the dataframe is displayed in the notebook. For the search result, we want to present a different formatting from what is available for dataframes, and we may also want to control which columns are displayed, or other aspects of the search results.\n",
    "\n",
    "### Outputting HTML\n",
    "Objects can control how they are displayed as HTML in a Jupyter notebook by implementing the `_repr_html_()` function. Some of the objects that we create in this project are meant to wrap a dataframe and control how they are displayed. `SearchResults` is one such object—it wraps the results dataframe and controls how it looks using `_repr_html_()`. `SearchResults` can actually be viewed as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>Investigation on demands for antenatal care se...</td>\n",
       "      <td>Objective To identify problems and demands for...</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Lessons learned from Korea: COVID-19 pandemic</td>\n",
       "      <td>Lessons learned from Korea: COVID-19 pandemic</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>Editorial. Impact of COVID-19 on neurosurgery ...</td>\n",
       "      <td>Editorial. Impact of COVID-19 on neurosurgery ...</td>\n",
       "      <td>3 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Editorial. Innovations in neurosurgical educat...</td>\n",
       "      <td>Editorial. Innovations in neurosurgical educat...</td>\n",
       "      <td>3 weeks ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<cord.cord19.SearchResults at 0x1574a9c7a20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.search('Mother to child', covid_related=True, num_results=4, view='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or an HTML table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       " <h4 class='cord'>Investigation on demands for antenatal care services among 2 002 pregnant women during the epidemic of coronavirus disease 2019 in Shanghai</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>4 months ago</span>\n",
       "     \n",
       "        <a href='#' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='cord_uid'>ndbc4kga</span>\n",
       "     \n",
       " </div>\n",
       " <div class='abstract'>Objective To identify problems and demands for antenatal care (ANC) among pregnant women in different trimesters of pregnancy in Shanghai for optimizing ANC service during the epidemic of coronavirus disease 2019 (COVID-19).\n",
       "Methods Organized by Maternal and Child Health Care institute in the 16 districts of Shanghai, a cross sectional study was conducted among pregnant women who came to pregnancy registration in the community health centers or attended ANC in maternity hospitals from February 7...</div>\n",
       " <div class='authors'>DU, Li; GU, Yibin; CUI, Mengqing; LI, Wenxian; WANG, Jie; ZHU, Liping; XU, Biao</div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Lessons learned from Korea: COVID-19 pandemic</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>1 month ago</span>\n",
       "     \n",
       "        <a href='http://doi.org/10.1017/ice.2020.104' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='cord_uid'>w0ud098l</span>\n",
       "     \n",
       " </div>\n",
       " <div class='abstract'>Lessons learned from Korea: COVID-19 pandemic</div>\n",
       " <div class='authors'>Moradi, Hazhir; Vaezi, Atefeh</div>\n",
       "\n",
       "\n",
       "\n",
       "<style>\n",
       ".authors{\n",
       "    margin: 4px 0px 15px;\n",
       "}\n",
       ".authors { color: #778899}\n",
       ".published {color: #2F4F4F; font-weight: bold; font-size: 0.9em; margin-right: 10px}\n",
       "#cord_uid{margin-left: 10px; font-weight: bold; font-size: 0.9em;}\n",
       "h2.cord, h3.cord, h4.cord {margin: 15px 0px 8px 0px}\n",
       "h4.cord{color:#008B8B; font-size: 1.1em; margin-top: 25px}\n",
       "div.abstract { margin: 10px 0px 2px}\n",
       "div#pubished_when{margin: 10px; display: block}\n",
       ".link-text {color: #808080; font-size: 0.9em}\n",
       "</style>"
      ],
      "text/plain": [
       "<cord.cord19.SearchResults at 0x1575abfce48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.search('Mother to child', covid_related=True, num_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Integrating your object with IPython](https://ipython.readthedocs.io/en/stable/config/integrating.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Dataframe style function\n",
    "Another great way to customize the look of a dataframe inside a notebook is to use the `dataframe.style` function. This pandas functionality is pretty powerful and can allow you to completely change how a dataframe is displayed in a notebook. \n",
    "\n",
    "In the _CORD_ library we wanted to style the results differently from regular dataframes, to improve on the look and feel, and to have the library stand out from the competition. The code below shows how the `display` function used the style function to change the styling of the results.\n",
    "\n",
    "```python\n",
    "    def display(self, *paper_ids):\n",
    "\n",
    "        # Look up the papers using the paperids and create a dataframe\n",
    "        _recs = []\n",
    "        for id in paper_ids:\n",
    "            paper = self[id]\n",
    "            _recs.append({'published': paper.metadata.published,\n",
    "                          'title': paper.title,\n",
    "                          'summary': paper.summary,\n",
    "                          'when': paper.metadata.when,\n",
    "                          'cord_uid': paper.cord_uid})\n",
    "        df = pd.DataFrame(_recs).sort_values(['published'], ascending=False).drop(columns=['published'])\n",
    "        \n",
    "        # Apply a style to a column\n",
    "        def highlight_cols(s):\n",
    "            return 'font-size: 1.1em; color: #008B8B; font-weight: bold'\n",
    "        \n",
    "        # Apply the style above to the title column of the dataframe and hide the index\n",
    "        return df.style.applymap(highlight_cols, subset=pd.IndexSlice[:, ['title']]).hide_index()\n",
    "\n",
    "```\n",
    "This is how the results are dispayed in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_3545aa3e_91f6_11ea_8ad9_7470fd726a31row0_col0 {\n",
       "            font-size:  1.1em;\n",
       "             color:  #008B8B;\n",
       "             font-weight:  bold;\n",
       "        }</style><table id=\"T_3545aa3e_91f6_11ea_8ad9_7470fd726a31\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >title</th>        <th class=\"col_heading level0 col1\" >summary</th>        <th class=\"col_heading level0 col2\" >when</th>        <th class=\"col_heading level0 col3\" >cord_uid</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_3545aa3e_91f6_11ea_8ad9_7470fd726a31row0_col0\" class=\"data row0 col0\" >Biochemical evidence for the presence of mixed membrane topologies of the severe acute respiratory syndrome coronavirus envelope protein expressed in mammalian cells</td>\n",
       "                        <td id=\"T_3545aa3e_91f6_11ea_8ad9_7470fd726a31row0_col1\" class=\"data row0 col1\" >Different coronavirus E proteins share striking similarities in biochemical properties and biological functions, but seem to adopt distinct membrane topology.\n",
       "In this report, we study the membrane topology of the SARS-CoV E protein by immunofluorescent staining of cells differentially permeabilized with detergents and proteinase K protection assay.\n",
       "It was revealed that both the N- and C-termini of the SARS-CoV E protein are exposed to the cytoplasmic side of the membranes (NcytoCcyto).\n",
       "Intriguingly, a minor proportion of the SARS-CoV E protein was found to be modified by N-linked glycosylation on Asn 66 and inserted into the membranes once with the C-terminus exposed to the luminal side.\n",
       "The presence of two distinct membrane topologies of the SARS-CoV E protein may provide a useful clue to the pathogenesis of SARS-CoV.</td>\n",
       "                        <td id=\"T_3545aa3e_91f6_11ea_8ad9_7470fd726a31row0_col2\" class=\"data row0 col2\" >14 years ago</td>\n",
       "                        <td id=\"T_3545aa3e_91f6_11ea_8ad9_7470fd726a31row0_col3\" class=\"data row0 col3\" >v3lbrzh8</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1575abfd7f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.display('v3lbrzh8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on styling dataframes see [Pandas Styling](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Search Widgets\n",
    "\n",
    "To create interactivity within the notebook, and to allow the user to perform interactive searches, we use `ipywidgets`.\n",
    "\n",
    "\n",
    "### Search Date Slider\n",
    "\n",
    "This widget displays a slider that allows a user to select relevant dates for the `Research` paper search:\n",
    "```python\n",
    "def SearchDatesSlider():\n",
    "    options = [(' 1951 ', '1951-01-01'), (' SARS 2003 ', '2002-11-01'),\n",
    "               (' H1N1 2009 ', '2009-04-01'), (' COVID 19 ', '2019-11-30'),\n",
    "               (' 2020 ', '2020-12-31')]\n",
    "    return widgets.SelectionRangeSlider(\n",
    "        options=options,\n",
    "        description='Dates',\n",
    "        disabled=False,\n",
    "        value=('2002-11-01', '2020-12-31'),\n",
    "        layout={'width': '480px'}\n",
    "    )\n",
    "```\n",
    "\n",
    "### SearchBar\n",
    "\n",
    "For the search bar we add a **Text**, **Button**, **Checkbox** and use **HBox** and **VBox** for layout.\n",
    "\n",
    "```python\n",
    "    def searchbar(self, initial_search_terms='', num_results=10, view=None):\n",
    "        text_input = widgets.Text(layout=widgets.Layout(width='400px'), value=initial_search_terms)\n",
    "\n",
    "        search_button = widgets.Button(description='Search', button_style='primary',\n",
    "                                       layout=widgets.Layout(width='100px'))\n",
    "        search_box = widgets.HBox(children=[text_input, search_button])\n",
    "\n",
    "        # A COVID-related checkbox\n",
    "        covid_related_CheckBox = widgets.Checkbox(description='Covid-19 related', value=False, disable=False)\n",
    "        checkboxes = widgets.HBox(children=[covid_related_CheckBox])\n",
    "\n",
    "        # A date slider to limit research papers to a date range\n",
    "        search_dates_slider = SearchDatesSlider()\n",
    "\n",
    "        search_widget = widgets.VBox([search_box, search_dates_slider, checkboxes])\n",
    "\n",
    "        output = widgets.Output()\n",
    "\n",
    "        def do_search():\n",
    "            search_terms = text_input.value.strip()\n",
    "            if search_terms and len(search_terms) >= 4:\n",
    "                start_date, end_date = search_dates_slider.value\n",
    "                self._search_papers(output=output, SearchTerms=search_terms, num_results=num_results, view=view,\n",
    "                                    start_date=start_date, end_date=end_date,\n",
    "                                    covid_related=covid_related_CheckBox.value)\n",
    "\n",
    "        def button_search_handler(btn):\n",
    "            with output:\n",
    "                clear_output()\n",
    "            do_search()\n",
    "\n",
    "        def text_search_handler(change):\n",
    "            if len(change['new'].split(' ')) != len(change['old'].split(' ')):\n",
    "                do_search()\n",
    "\n",
    "        def date_handler(change):\n",
    "            do_search()\n",
    "\n",
    "        def checkbox_handler(change):\n",
    "            do_search()\n",
    "\n",
    "        search_button.on_click(button_search_handler)\n",
    "        text_input.observe(text_search_handler, names='value')\n",
    "        search_dates_slider.observe(date_handler, names='value')\n",
    "        covid_related_CheckBox.observe(checkbox_handler, names='value')\n",
    "\n",
    "        display(search_widget)\n",
    "        display(output)\n",
    "\n",
    "        # Show the initial terms\n",
    "        if initial_search_terms:\n",
    "            do_search()\n",
    "\n",
    "```\n",
    "\n",
    "Now we can see the search bar in action. It updates as you change the selections in the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29636607f9848e88d140ccd011cbc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='Cruise ship', layout=Layout(width='400px')), Button(button_style='pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6941893c025045829d7c44caa6c2eaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "papers.searchbar('Cruise ship', num_results=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Risk factors](../images/riskfactors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting  Research Papers\n",
    "\n",
    "There are many ways to select subsets of research papers including:\n",
    "\n",
    "- **Papers since SARS**  `research_papers.since_sars()`\n",
    "- **Papers since SARS-COV-2** `research_papers.since_sarscov2()`\n",
    "- **Papers before SARS** `research_papers.before_sars()`\n",
    "- **Papers before SARS-COV-2** `research_papers.before_sarscov2()`\n",
    "- **Papers before a date** `research_papers.before('1989-09-12')`\n",
    "- **Papers after a date** `research_papers.after('1989-09-12')`\n",
    "- **Papers that contains a string** \n",
    "- **Papers that match a string (using regex)** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers published since SARS-COV-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>CORD 19 Research Papers</h3>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Papers</th>\n",
       "      <th>Oldest</th>\n",
       "      <th>Newest</th>\n",
       "      <th>SARS-COV-2</th>\n",
       "      <th>SARS</th>\n",
       "      <th>Coronavirus</th>\n",
       "      <th>Virus</th>\n",
       "      <th>Antivirals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>316</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>176</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<hr/>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Focusing on Families and Visitors Reduces Heal...</td>\n",
       "      <td>Healthcare-associated respiratory viral infect...</td>\n",
       "      <td>Pediatr Qual Saf</td>\n",
       "      <td>Linam, W. Matthew; Marrero, Elizabeth M.; Hone...</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Willingness to Self-Isolate When Facing a Pand...</td>\n",
       "      <td>Infected people are isolated to minimize the s...</td>\n",
       "      <td>Int J Environ Res Public Health</td>\n",
       "      <td>Zhang, Xiaojun; Wang, Fanfan; Zhu, Changwen; W...</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Causes of fever in Gabonese children: a cross-...</td>\n",
       "      <td>The causes of infections in pediatric populati...</td>\n",
       "      <td>Sci Rep</td>\n",
       "      <td>Fernandes, José Francisco; Held, Jana; Dorn, M...</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Loop-Mediated Isothermal Amplification (LAMP) ...</td>\n",
       "      <td>The recent outbreak of Zika virus (ZIKV) in th...</td>\n",
       "      <td>Viruses</td>\n",
       "      <td>da Silva, Severino Jefferson Ribeiro; Pardee, ...</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Innate Immunity and Pathogenesis of Biliary At...</td>\n",
       "      <td>Biliary atresia (BA) is a devastating fibro-in...</td>\n",
       "      <td>Front Immunol</td>\n",
       "      <td>Ortiz-Perez, Ana; Donnelly, Bryan; Temple, Hal...</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>MERS-CoV as an emerging respiratory illness: A...</td>\n",
       "      <td>Introduction Middle East Respiratory Coronavi...</td>\n",
       "      <td>Travel Medicine and Infectious Disease</td>\n",
       "      <td>Baharoon, Salim; Memish, Ziad A.</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Mass gathering events and reducing further glo...</td>\n",
       "      <td>Mass gathering events and reducing further glo...</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>McCloskey, Brian; Zumla, Alimuddin; Ippolito, ...</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>4 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>New insights on the antiviral effects of chlor...</td>\n",
       "      <td>ABSTRACT Recently, a novel coronavirus (2019-n...</td>\n",
       "      <td>International Journal of Antimicrobial Agents</td>\n",
       "      <td>Devaux, Christian A.; Rolain, Jean-Marc; Colso...</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>2 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>A British Society of Thoracic Imaging statemen...</td>\n",
       "      <td>A British Society of Thoracic Imaging statemen...</td>\n",
       "      <td>Clinical Radiology</td>\n",
       "      <td>Nair, A.; Rodrigues, J.C.L.; Hare, S.; Edey, A...</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>in 3 weeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>Antiviral responses against chicken respirator...</td>\n",
       "      <td>Some of the respiratory viral infections in c...</td>\n",
       "      <td>Cytokine</td>\n",
       "      <td>Barjesteh, Neda; O'Dowd, Kelsey; Vahedi, Seyed...</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 6 columns</p>\n",
       "</div>\n",
       "<style>\n",
       "h3 {color: #4169E1}\n",
       "</style>"
      ],
      "text/plain": [
       "<cord.cord19.ResearchPapers at 0x1575a90e9e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.since_sarscov2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers with \"bats\" in the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>CORD 19 Research Papers</h3>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Papers</th>\n",
       "      <th>Oldest</th>\n",
       "      <th>Newest</th>\n",
       "      <th>SARS-COV-2</th>\n",
       "      <th>SARS</th>\n",
       "      <th>Coronavirus</th>\n",
       "      <th>Virus</th>\n",
       "      <th>Antivirals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>3</td>\n",
       "      <td>2010-08-15</td>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<hr/>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Prevalence, diversity, and host associations o...</td>\n",
       "      <td>Bartonella infections were investigated in sev...</td>\n",
       "      <td>PLoS Negl Trop Dis</td>\n",
       "      <td>Urushadze, Lela; Bai, Ying; Osikowicz, Lynn; M...</td>\n",
       "      <td>2017-04-11</td>\n",
       "      <td>3 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Detection of adenovirus, papillomavirus and pa...</td>\n",
       "      <td>Bats play a significant role in maintaining th...</td>\n",
       "      <td>Arch Virol</td>\n",
       "      <td>Finoketti, Fernando; dos Santos, Raíssa Nunes;...</td>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>1 year ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>Identification and complete genome analysis of...</td>\n",
       "      <td>Among 489 bats of 11 species in China, three ...</td>\n",
       "      <td>Virology</td>\n",
       "      <td>Lau, Susanna K.P.; Woo, Patrick C.Y.; Wong, Be...</td>\n",
       "      <td>2010-08-15</td>\n",
       "      <td>10 years ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       "h3 {color: #4169E1}\n",
       "</style>"
      ],
      "text/plain": [
       "<cord.cord19.ResearchPapers at 0x1575a90ee80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.contains('bats', column='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers with Brian Mcloskey as an author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>CORD 19 Research Papers</h3>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Papers</th>\n",
       "      <th>Oldest</th>\n",
       "      <th>Newest</th>\n",
       "      <th>SARS-COV-2</th>\n",
       "      <th>SARS</th>\n",
       "      <th>Coronavirus</th>\n",
       "      <th>Virus</th>\n",
       "      <th>Antivirals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<hr/>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>The rise of Zika infection and microcephaly: w...</td>\n",
       "      <td>Objectives To consider why Zika was declared ...</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>McCloskey, B.; Endericks, T.</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>3 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Mass gathering events and reducing further glo...</td>\n",
       "      <td>Mass gathering events and reducing further glo...</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>McCloskey, Brian; Zumla, Alimuddin; Ippolito, ...</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>4 weeks ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       "h3 {color: #4169E1}\n",
       "</style>"
      ],
      "text/plain": [
       "<cord.cord19.ResearchPapers at 0x1575a944208>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.match('.*McCloskey, B', column='authors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a single research paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ResearchPapers` class implements `__get_item__()` so a single `ResearchPaper` can be accessed using the numeric index of the paper as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 class=\"cord\">A model of tripeptidyl-peptidase I (CLN2), a ubiquitous and highly conserved member of the sedolisin family of serine-carboxyl peptidases</h4>\n",
       "<div><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published</th>\n",
       "      <th>authors</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>2003-11-11</td>\n",
       "      <td>Wlodawer, Alexander; Durell, Stewart R; Li, Mi...</td>\n",
       "      <td>5o38ihe0</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><div>\n",
       "<h4 class=\"summary_title\">Summary</h4>\n",
       "<div id=\"summary\">: Tripeptidyl-peptidase I, also known as CLN2, is a member of the family of sedolisins (serine-carboxyl peptidases).\n",
       "Similar enzymes have been found in the genomic sequences of several species, but neither systematic analyses of their distribution nor modeling of their structures have been previously attempted.\n",
       "RESULTS: We have analyzed the presence of orthologs of human CLN2 in the genomic sequences of a number of eukaryotic species.\n",
       "Enzymes with sequences sharing over 80% identity have been found in the genomes of macaque, mouse, rat, dog, and cow.\n",
       "A three-dimensional model of human CLN2 was built based mainly on the homology with Pseudomonas sp.\n",
       "The model presented here indicates a very open and accessible active site that is almost completely conserved among all known CLN2 enzymes.</div>\n",
       "<style>\n",
       "h2.cord, h3.cord, h4.cord {margin: 15px 0px 8px 0px}\n",
       "h4.cord{color:#008B8B; font-size: 1.1em; margin-top: 15px}\n",
       "h4.summary_title{margin-top: 10px}\n",
       "#summary {max-height:160px; border-bottom: 1px solid #696969;}\n",
       "</style>"
      ],
      "text/plain": [
       "<cord.cord19.Paper at 0x1575a944da0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's preferable to access a paper using the **cord_uid** since it is a stable identifier. `papers[\"5o38ihe0\"]` referes to the same research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 class=\"cord\">A model of tripeptidyl-peptidase I (CLN2), a ubiquitous and highly conserved member of the sedolisin family of serine-carboxyl peptidases</h4>\n",
       "<div><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published</th>\n",
       "      <th>authors</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>2003-11-11</td>\n",
       "      <td>Wlodawer, Alexander; Durell, Stewart R; Li, Mi...</td>\n",
       "      <td>5o38ihe0</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><div>\n",
       "<h4 class=\"summary_title\">Summary</h4>\n",
       "<div id=\"summary\">: Tripeptidyl-peptidase I, also known as CLN2, is a member of the family of sedolisins (serine-carboxyl peptidases).\n",
       "Similar enzymes have been found in the genomic sequences of several species, but neither systematic analyses of their distribution nor modeling of their structures have been previously attempted.\n",
       "RESULTS: We have analyzed the presence of orthologs of human CLN2 in the genomic sequences of a number of eukaryotic species.\n",
       "Enzymes with sequences sharing over 80% identity have been found in the genomes of macaque, mouse, rat, dog, and cow.\n",
       "A three-dimensional model of human CLN2 was built based mainly on the homology with Pseudomonas sp.\n",
       "The model presented here indicates a very open and accessible active site that is almost completely conserved among all known CLN2 enzymes.</div>\n",
       "<style>\n",
       "h2.cord, h3.cord, h4.cord {margin: 15px 0px 8px 0px}\n",
       "h4.cord{color:#008B8B; font-size: 1.1em; margin-top: 15px}\n",
       "h4.summary_title{margin-top: 10px}\n",
       "#summary {max-height:160px; border-bottom: 1px solid #696969;}\n",
       "</style>"
      ],
      "text/plain": [
       "<cord.cord19.Paper at 0x1575a90e3c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers['5o38ihe0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing getitem\n",
    "The implementation of `__getitem__()` is simple:\n",
    "\n",
    "```python\n",
    "    def __getitem__(self, item):\n",
    "        if isinstance(item, int):\n",
    "            paper = self.metadata.iloc[item]\n",
    "        else:\n",
    "            paper = self.metadata[self.metadata.cord_uid == item]\n",
    "```\n",
    "\n",
    "The main view of a research paper is the overview, as shown above. This shows a formatted collection of the paper's important fields. There are other views or attributes of research papers, including:\n",
    "\n",
    "- **Overview**: A nicely formatted view of the paper's important fields\n",
    "- **Abstract**: The paper's abstract\n",
    "- **Summary**: A summary of the paper's abstract using the `TextRank` algorithm\n",
    "- **Text**: The text in the paper\n",
    "- **HTML**: The contents of the paper as somewhat nicely formatted HTML\n",
    "- **Text Summary**: The text of the paper, summarized using the `TextRank` algorithm\n",
    "\n",
    "This is implemented in the following function:\n",
    "\n",
    "```python\n",
    "paper = research_papers['asf5c7xu']\n",
    "\n",
    "def view_paper(ViewPaperAs):\n",
    "    if ViewPaperAs == 'Overview':\n",
    "        display(paper)\n",
    "    elif ViewPaperAs == 'Abstract':\n",
    "        display(paper.abstract)\n",
    "    elif ViewPaperAs == 'Summary of Abstract':\n",
    "        display(paper.summary)\n",
    "    elif ViewPaperAs == 'HTML':\n",
    "        display(paper.html)\n",
    "    elif ViewPaperAs == 'Text':\n",
    "        display(paper.text)\n",
    "    elif ViewPaperAs == 'Summary of Text':\n",
    "        display(paper.text_summary)\n",
    "    \n",
    "interact(view_paper,\n",
    "         ViewPaperAs=['Overview', # Show an overview of the paper's important fields and statistics\n",
    "                      'Abstract', # Show the paper's abstract\n",
    "                      'Summary of Abstract', # Show a summary of the paper's abstract\n",
    "                      'HTML', # Show the paper's contents as (slightly) formatted HTML\n",
    "                      'Text', # Show the paper's contents\n",
    "                      'Summary of Text' # Show a summary of the paper's content\n",
    "                     ]\n",
    "        );\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook we showed you how to use search and NLP techniques to build a simple search engine and UI over a set of documents. Hopefully, it can help you create your own solution if you are interested in contributing to the same CORD research paper dataset. However, the code and techniques learned here can be applied to other use cases, so feel free to adapt it to your own purposes.\n",
    "\n",
    "![Search2d](../images/medicalstaff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [CORD-19 Research Paper Challenge on Kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)\n",
    "- [CORD library on Github](https://github.com/dgunning/cord19)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cord",
   "language": "python",
   "name": "cord"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
